{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9820d842",
   "metadata": {},
   "source": [
    "# ДЗ 6\n",
    "Выполнили: Добрынина Анастасия, Тринихина Таисия\n",
    "## Задача\n",
    "Нужно решить задачу классификации отзывов о фильмах на положительные и отрицательные. Цель - получить как можно более высокое качество ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb4f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a531dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cda99e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I fail to see the appeal of this series (which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>According to the budget information given on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I was looking forward to seeing Amanda Peet in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>This movie is very disappointing for one who h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>There is absolutely no doubt that this version...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   0  I fail to see the appeal of this series (which...\n",
       "1   1  According to the budget information given on t...\n",
       "2   2  I was looking forward to seeing Amanda Peet in...\n",
       "3   3  This movie is very disappointing for one who h...\n",
       "4   4  There is absolutely no doubt that this version..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae41a475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What a disappointment... admittedly the best o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a pale imitation of the Die Hard franc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This good-guy-vs-the-evil-tyrant story, set in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>This is a documentary I came across by chance ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>This installment of Masters of Horror was terr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  answer\n",
       "0   0  What a disappointment... admittedly the best o...       0\n",
       "1   1  This is a pale imitation of the Die Hard franc...       0\n",
       "2   2  This good-guy-vs-the-evil-tyrant story, set in...       0\n",
       "3   3  This is a documentary I came across by chance ...       1\n",
       "4   4  This installment of Masters of Horror was terr...       0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4696cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      25000 non-null  int64 \n",
      " 1   text    25000 non-null  object\n",
      " 2   answer  25000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 586.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()\n",
    "# убедимся, что нет нулевых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f2117b",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d81c3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70aec0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    lemmas = ''\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word.isalpha():\n",
    "            word = morph.parse(word.lower())[0]\n",
    "            lemma = word.normal_form\n",
    "            if lemma not in stops:\n",
    "                lemmas += lemma + ' '\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2200c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\79998\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83792c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем параметры (добавим стоп-слова)\n",
    "stops = stopwords.words(\"english\")\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000, # в случае плохого качества можно увеличить\n",
    "    min_df=5,\n",
    "    analyzer=\"word\", # анализировать по словам или по символам (char)\n",
    "    stop_words=stops # передаём список стоп-слов из NLTK\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29bfdbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = []\n",
    "for i in train['text']:\n",
    "    lemmas.append(preprocess_text(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5abdc3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['lemmas'] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48ddf13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lemmas = train.drop('text',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e418f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>disappointment admittedly best prequels story ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pale imitation die hard franchise sucks low am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>story set century russia may attempt extend st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>documentary came across chance uk tv channel s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>installment masters horror terrible apparently...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>0</td>\n",
       "      <td>horrible script apparently directed one marine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>1</td>\n",
       "      <td>five years tenko survivors returning home mari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>1</td>\n",
       "      <td>understand critic evaluating quality acting fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>0</td>\n",
       "      <td>movie pretentious foppish right funny filming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>0</td>\n",
       "      <td>movie truly amazing years acquired taste japan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  answer                                             lemmas\n",
       "0          0       0  disappointment admittedly best prequels story ...\n",
       "1          1       0  pale imitation die hard franchise sucks low am...\n",
       "2          2       0  story set century russia may attempt extend st...\n",
       "3          3       1  documentary came across chance uk tv channel s...\n",
       "4          4       0  installment masters horror terrible apparently...\n",
       "...      ...     ...                                                ...\n",
       "24995  24995       0  horrible script apparently directed one marine...\n",
       "24996  24996       1  five years tenko survivors returning home mari...\n",
       "24997  24997       1  understand critic evaluating quality acting fi...\n",
       "24998  24998       0  movie pretentious foppish right funny filming ...\n",
       "24999  24999       0  movie truly amazing years acquired taste japan...\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc9e9cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# обучаем TF-IDF\n",
    "X = tfidf.fit_transform(train_lemmas['lemmas']).todense()\n",
    "\n",
    "\n",
    "new_cols=tfidf.get_feature_names_out()\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef89a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf = train_lemmas.drop('lemmas',axis=1)\n",
    "#присоединяет tf-idf в датасет\n",
    "train_tfidf = train_tfidf.join(pd.DataFrame(X, columns=new_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42dc79ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>acted</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>zombie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.122382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  answer      able  absolutely    across  act   acted    acting  \\\n",
       "0          0       0  0.000000         0.0  0.000000  0.0  0.0000  0.000000   \n",
       "1          1       0  0.000000         0.0  0.000000  0.0  0.0000  0.000000   \n",
       "2          2       0  0.000000         0.0  0.000000  0.0  0.0000  0.000000   \n",
       "3          3       1  0.125887         0.0  0.134343  0.0  0.0000  0.000000   \n",
       "4          4       0  0.000000         0.0  0.000000  0.0  0.0000  0.000000   \n",
       "...      ...     ...       ...         ...       ...  ...     ...       ...   \n",
       "24995  24995       0  0.000000         0.0  0.000000  0.0  0.0000  0.000000   \n",
       "24996  24996       1  0.000000         0.0  0.000000  0.0  0.1598  0.000000   \n",
       "24997  24997       1  0.000000         0.0  0.000000  0.0  0.0000  0.122382   \n",
       "24998  24998       0  0.000000         0.0  0.000000  0.0  0.0000  0.000000   \n",
       "24999  24999       0  0.000000         0.0  0.000000  0.0  0.0000  0.000000   \n",
       "\n",
       "         action  actor  ...  wrote  yeah      year     years  yes       yet  \\\n",
       "0      0.000000    0.0  ...    0.0   0.0  0.000000  0.123399  0.0  0.000000   \n",
       "1      0.000000    0.0  ...    0.0   0.0  0.000000  0.000000  0.0  0.000000   \n",
       "2      0.177493    0.0  ...    0.0   0.0  0.000000  0.000000  0.0  0.171692   \n",
       "3      0.000000    0.0  ...    0.0   0.0  0.000000  0.000000  0.0  0.000000   \n",
       "4      0.103645    0.0  ...    0.0   0.0  0.000000  0.000000  0.0  0.000000   \n",
       "...         ...    ...  ...    ...   ...       ...       ...  ...       ...   \n",
       "24995  0.000000    0.0  ...    0.0   0.0  0.162739  0.000000  0.0  0.000000   \n",
       "24996  0.000000    0.0  ...    0.0   0.0  0.000000  0.196883  0.0  0.000000   \n",
       "24997  0.000000    0.0  ...    0.0   0.0  0.000000  0.000000  0.0  0.000000   \n",
       "24998  0.000000    0.0  ...    0.0   0.0  0.000000  0.000000  0.0  0.000000   \n",
       "24999  0.000000    0.0  ...    0.0   0.0  0.000000  0.164135  0.0  0.000000   \n",
       "\n",
       "       york     young  younger  zombie  \n",
       "0       0.0  0.000000      0.0     0.0  \n",
       "1       0.0  0.000000      0.0     0.0  \n",
       "2       0.0  0.000000      0.0     0.0  \n",
       "3       0.0  0.000000      0.0     0.0  \n",
       "4       0.0  0.000000      0.0     0.0  \n",
       "...     ...       ...      ...     ...  \n",
       "24995   0.0  0.000000      0.0     0.0  \n",
       "24996   0.0  0.000000      0.0     0.0  \n",
       "24997   0.0  0.000000      0.0     0.0  \n",
       "24998   0.0  0.000000      0.0     0.0  \n",
       "24999   0.0  0.182206      0.0     0.0  \n",
       "\n",
       "[25000 rows x 1002 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_tfidf.dropna() #кажется, ничего не изменилось\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa5818e",
   "metadata": {},
   "source": [
    "подготовтим аналогично тестовые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3f77137",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_test = []\n",
    "for i in test['text']:\n",
    "    lemmas_test.append(preprocess_text(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "184628c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['lemmas'] = lemmas_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdc7c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lemmas = test.drop('text',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74ecb7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# обучаем TF-IDF\n",
    "X1 = tfidf.fit_transform(test_lemmas['lemmas']).todense()\n",
    "\n",
    "\n",
    "new_cols=tfidf.get_feature_names_out()\n",
    "\n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c441d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf = test_lemmas.drop('lemmas',axis=1)\n",
    "#присоединяет tf-idf в датасет\n",
    "test_tfidf = test_tfidf.join(pd.DataFrame(X1, columns=new_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a84a3849",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accent</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>acted</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>zombie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100236</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  able  absolutely  accent  across       act  acted    acting  \\\n",
       "0          0   0.0    0.000000     0.0     0.0  0.000000    0.0  0.000000   \n",
       "1          1   0.0    0.000000     0.0     0.0  0.000000    0.0  0.158219   \n",
       "2          2   0.0    0.000000     0.0     0.0  0.290504    0.0  0.044246   \n",
       "3          3   0.0    0.000000     0.0     0.0  0.000000    0.0  0.000000   \n",
       "4          4   0.0    0.193430     0.0     0.0  0.000000    0.0  0.000000   \n",
       "...      ...   ...         ...     ...     ...       ...    ...       ...   \n",
       "24995  24995   0.0    0.000000     0.0     0.0  0.179958    0.0  0.000000   \n",
       "24996  24996   0.0    0.000000     0.0     0.0  0.000000    0.0  0.000000   \n",
       "24997  24997   0.0    0.000000     0.0     0.0  0.000000    0.0  0.000000   \n",
       "24998  24998   0.0    0.161324     0.0     0.0  0.000000    0.0  0.000000   \n",
       "24999  24999   0.0    0.000000     0.0     0.0  0.000000    0.0  0.000000   \n",
       "\n",
       "         action  actor  ...  wrong  wrote  yeah  year     years  yes  yet  \\\n",
       "0      0.000000    0.0  ...    0.0    0.0   0.0   0.0  0.000000  0.0  0.0   \n",
       "1      0.000000    0.0  ...    0.0    0.0   0.0   0.0  0.000000  0.0  0.0   \n",
       "2      0.000000    0.0  ...    0.0    0.0   0.0   0.0  0.000000  0.0  0.0   \n",
       "3      0.146824    0.0  ...    0.0    0.0   0.0   0.0  0.000000  0.0  0.0   \n",
       "4      0.000000    0.0  ...    0.0    0.0   0.0   0.0  0.000000  0.0  0.0   \n",
       "...         ...    ...  ...    ...    ...   ...   ...       ...  ...  ...   \n",
       "24995  0.000000    0.0  ...    0.0    0.0   0.0   0.0  0.000000  0.0  0.0   \n",
       "24996  0.000000    0.0  ...    0.0    0.0   0.0   0.0  0.000000  0.0  0.0   \n",
       "24997  0.000000    0.0  ...    0.0    0.0   0.0   0.0  0.000000  0.0  0.0   \n",
       "24998  0.000000    0.0  ...    0.0    0.0   0.0   0.0  0.123419  0.0  0.0   \n",
       "24999  0.142100    0.0  ...    0.0    0.0   0.0   0.0  0.000000  0.0  0.0   \n",
       "\n",
       "       york     young  zombie  \n",
       "0       0.0  0.000000     0.0  \n",
       "1       0.0  0.100236     0.0  \n",
       "2       0.0  0.000000     0.0  \n",
       "3       0.0  0.000000     0.0  \n",
       "4       0.0  0.000000     0.0  \n",
       "...     ...       ...     ...  \n",
       "24995   0.0  0.000000     0.0  \n",
       "24996   0.0  0.000000     0.0  \n",
       "24997   0.0  0.000000     0.0  \n",
       "24998   0.0  0.000000     0.0  \n",
       "24999   0.0  0.000000     0.0  \n",
       "\n",
       "[25000 rows x 1001 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test_tfidf.dropna() #кажется, ничего не изменилось\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19512ed0",
   "metadata": {},
   "source": [
    "Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c338af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(X['answer'] == 0)\n",
    "X_train = X.drop('answer',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "716a08e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c45f1a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79998\\anaconda3\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- accent\n",
      "- adult\n",
      "- barely\n",
      "- bought\n",
      "- cat\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- alien\n",
      "- band\n",
      "- ben\n",
      "- charles\n",
      "- christmas\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009396ef",
   "metadata": {},
   "source": [
    "Проверка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83e11a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79998\\anaconda3\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- accent\n",
      "- adult\n",
      "- barely\n",
      "- bought\n",
      "- cat\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- alien\n",
      "- band\n",
      "- ben\n",
      "- charles\n",
      "- christmas\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c4ceae8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and binary targets"
     ]
    }
   ],
   "source": [
    "accuracy_score(X_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5db8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(X_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bb226c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False,  True])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns == X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d07148",
   "metadata": {},
   "source": [
    "Нужно стандартизировать (наверное)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac60c3e4",
   "metadata": {},
   "source": [
    "Что происходит дальше, я не знаю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4dba4f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>80</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>zombie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12499.500000</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.005381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.014187</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.009352</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.011615</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.002772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7217.022701</td>\n",
       "      <td>0.044001</td>\n",
       "      <td>0.022137</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>0.022483</td>\n",
       "      <td>0.026784</td>\n",
       "      <td>0.027486</td>\n",
       "      <td>0.030999</td>\n",
       "      <td>0.024725</td>\n",
       "      <td>0.028057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>0.021677</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.039323</td>\n",
       "      <td>0.029511</td>\n",
       "      <td>0.032720</td>\n",
       "      <td>0.025650</td>\n",
       "      <td>0.039327</td>\n",
       "      <td>0.021301</td>\n",
       "      <td>0.031430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6249.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12499.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18749.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24999.000000</td>\n",
       "      <td>0.626743</td>\n",
       "      <td>0.434690</td>\n",
       "      <td>0.486640</td>\n",
       "      <td>0.420091</td>\n",
       "      <td>0.741168</td>\n",
       "      <td>0.463374</td>\n",
       "      <td>0.406573</td>\n",
       "      <td>0.490208</td>\n",
       "      <td>0.657187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487124</td>\n",
       "      <td>0.500716</td>\n",
       "      <td>0.447055</td>\n",
       "      <td>0.500028</td>\n",
       "      <td>0.466081</td>\n",
       "      <td>0.489667</td>\n",
       "      <td>0.678546</td>\n",
       "      <td>0.591885</td>\n",
       "      <td>0.492987</td>\n",
       "      <td>0.872346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id            10            15            20            30  \\\n",
       "count  25000.000000  25000.000000  25000.000000  25000.000000  25000.000000   \n",
       "mean   12499.500000      0.014760      0.002810      0.003531      0.003184   \n",
       "std     7217.022701      0.044001      0.022137      0.023430      0.022483   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%     6249.750000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    12499.500000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    18749.250000      0.000000      0.000000      0.000000      0.000000   \n",
       "max    24999.000000      0.626743      0.434690      0.486640      0.420091   \n",
       "\n",
       "                 80          able    absolutely        across           act  \\\n",
       "count  25000.000000  25000.000000  25000.000000  25000.000000  25000.000000   \n",
       "mean       0.003452      0.005526      0.006985      0.004308      0.005381   \n",
       "std        0.026784      0.027486      0.030999      0.024725      0.028057   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.741168      0.463374      0.406573      0.490208      0.657187   \n",
       "\n",
       "       ...         wrote          yeah          year         years  \\\n",
       "count  ...  25000.000000  25000.000000  25000.000000  25000.000000   \n",
       "mean   ...      0.002887      0.002680      0.008403      0.014187   \n",
       "std    ...      0.021672      0.021677      0.033600      0.039323   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      0.487124      0.500716      0.447055      0.500028   \n",
       "\n",
       "                yes           yet          york         young       younger  \\\n",
       "count  25000.000000  25000.000000  25000.000000  25000.000000  25000.000000   \n",
       "mean       0.006313      0.009352      0.003438      0.011615      0.002769   \n",
       "std        0.029511      0.032720      0.025650      0.039327      0.021301   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.466081      0.489667      0.678546      0.591885      0.492987   \n",
       "\n",
       "             zombie  \n",
       "count  25000.000000  \n",
       "mean       0.002772  \n",
       "std        0.031430  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        0.872346  \n",
       "\n",
       "[8 rows x 1001 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ba75ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X.select_dtypes(\"number\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41ec65e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sc.transform(X.select_dtypes(\"number\"))\n",
    "X_train = pd.DataFrame(X)\n",
    "X_train.columns = X.select_dtypes(\"number\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5910b404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>80</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>zombie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>2.500000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-6.116885e-17</td>\n",
       "      <td>8.666667e-16</td>\n",
       "      <td>4.307132e-16</td>\n",
       "      <td>1.140210e-15</td>\n",
       "      <td>-6.262546e-17</td>\n",
       "      <td>-1.919913e-15</td>\n",
       "      <td>-4.298983e-16</td>\n",
       "      <td>6.954415e-16</td>\n",
       "      <td>-6.350676e-16</td>\n",
       "      <td>-2.079277e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.933009e-16</td>\n",
       "      <td>5.111966e-16</td>\n",
       "      <td>2.106182e-16</td>\n",
       "      <td>6.824230e-16</td>\n",
       "      <td>-9.303203e-16</td>\n",
       "      <td>-8.339951e-16</td>\n",
       "      <td>-2.711003e-15</td>\n",
       "      <td>1.051639e-15</td>\n",
       "      <td>-2.090579e-15</td>\n",
       "      <td>5.891365e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "      <td>1.000020e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.731982e+00</td>\n",
       "      <td>-3.354625e-01</td>\n",
       "      <td>-1.269367e-01</td>\n",
       "      <td>-1.507177e-01</td>\n",
       "      <td>-1.416245e-01</td>\n",
       "      <td>-1.288965e-01</td>\n",
       "      <td>-2.010529e-01</td>\n",
       "      <td>-2.253249e-01</td>\n",
       "      <td>-1.742366e-01</td>\n",
       "      <td>-1.918075e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.332262e-01</td>\n",
       "      <td>-1.236582e-01</td>\n",
       "      <td>-2.500917e-01</td>\n",
       "      <td>-3.607842e-01</td>\n",
       "      <td>-2.139107e-01</td>\n",
       "      <td>-2.858240e-01</td>\n",
       "      <td>-1.340179e-01</td>\n",
       "      <td>-2.953617e-01</td>\n",
       "      <td>-1.299937e-01</td>\n",
       "      <td>-8.818208e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.659908e-01</td>\n",
       "      <td>-3.354625e-01</td>\n",
       "      <td>-1.269367e-01</td>\n",
       "      <td>-1.507177e-01</td>\n",
       "      <td>-1.416245e-01</td>\n",
       "      <td>-1.288965e-01</td>\n",
       "      <td>-2.010529e-01</td>\n",
       "      <td>-2.253249e-01</td>\n",
       "      <td>-1.742366e-01</td>\n",
       "      <td>-1.918075e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.332262e-01</td>\n",
       "      <td>-1.236582e-01</td>\n",
       "      <td>-2.500917e-01</td>\n",
       "      <td>-3.607842e-01</td>\n",
       "      <td>-2.139107e-01</td>\n",
       "      <td>-2.858240e-01</td>\n",
       "      <td>-1.340179e-01</td>\n",
       "      <td>-2.953617e-01</td>\n",
       "      <td>-1.299937e-01</td>\n",
       "      <td>-8.818208e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.354625e-01</td>\n",
       "      <td>-1.269367e-01</td>\n",
       "      <td>-1.507177e-01</td>\n",
       "      <td>-1.416245e-01</td>\n",
       "      <td>-1.288965e-01</td>\n",
       "      <td>-2.010529e-01</td>\n",
       "      <td>-2.253249e-01</td>\n",
       "      <td>-1.742366e-01</td>\n",
       "      <td>-1.918075e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.332262e-01</td>\n",
       "      <td>-1.236582e-01</td>\n",
       "      <td>-2.500917e-01</td>\n",
       "      <td>-3.607842e-01</td>\n",
       "      <td>-2.139107e-01</td>\n",
       "      <td>-2.858240e-01</td>\n",
       "      <td>-1.340179e-01</td>\n",
       "      <td>-2.953617e-01</td>\n",
       "      <td>-1.299937e-01</td>\n",
       "      <td>-8.818208e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.659908e-01</td>\n",
       "      <td>-3.354625e-01</td>\n",
       "      <td>-1.269367e-01</td>\n",
       "      <td>-1.507177e-01</td>\n",
       "      <td>-1.416245e-01</td>\n",
       "      <td>-1.288965e-01</td>\n",
       "      <td>-2.010529e-01</td>\n",
       "      <td>-2.253249e-01</td>\n",
       "      <td>-1.742366e-01</td>\n",
       "      <td>-1.918075e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.332262e-01</td>\n",
       "      <td>-1.236582e-01</td>\n",
       "      <td>-2.500917e-01</td>\n",
       "      <td>-3.607842e-01</td>\n",
       "      <td>-2.139107e-01</td>\n",
       "      <td>-2.858240e-01</td>\n",
       "      <td>-1.340179e-01</td>\n",
       "      <td>-2.953617e-01</td>\n",
       "      <td>-1.299937e-01</td>\n",
       "      <td>-8.818208e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.731982e+00</td>\n",
       "      <td>1.390879e+01</td>\n",
       "      <td>1.950984e+01</td>\n",
       "      <td>2.061985e+01</td>\n",
       "      <td>1.854347e+01</td>\n",
       "      <td>2.754411e+01</td>\n",
       "      <td>1.665766e+01</td>\n",
       "      <td>1.289073e+01</td>\n",
       "      <td>1.965274e+01</td>\n",
       "      <td>2.323167e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.234428e+01</td>\n",
       "      <td>2.297604e+01</td>\n",
       "      <td>1.305537e+01</td>\n",
       "      <td>1.235532e+01</td>\n",
       "      <td>1.557978e+01</td>\n",
       "      <td>1.467985e+01</td>\n",
       "      <td>2.632046e+01</td>\n",
       "      <td>1.475529e+01</td>\n",
       "      <td>2.301481e+01</td>\n",
       "      <td>2.766763e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id            10            15            20            30  \\\n",
       "count  2.500000e+04  2.500000e+04  2.500000e+04  2.500000e+04  2.500000e+04   \n",
       "mean  -6.116885e-17  8.666667e-16  4.307132e-16  1.140210e-15 -6.262546e-17   \n",
       "std    1.000020e+00  1.000020e+00  1.000020e+00  1.000020e+00  1.000020e+00   \n",
       "min   -1.731982e+00 -3.354625e-01 -1.269367e-01 -1.507177e-01 -1.416245e-01   \n",
       "25%   -8.659908e-01 -3.354625e-01 -1.269367e-01 -1.507177e-01 -1.416245e-01   \n",
       "50%    0.000000e+00 -3.354625e-01 -1.269367e-01 -1.507177e-01 -1.416245e-01   \n",
       "75%    8.659908e-01 -3.354625e-01 -1.269367e-01 -1.507177e-01 -1.416245e-01   \n",
       "max    1.731982e+00  1.390879e+01  1.950984e+01  2.061985e+01  1.854347e+01   \n",
       "\n",
       "                 80          able    absolutely        across           act  \\\n",
       "count  2.500000e+04  2.500000e+04  2.500000e+04  2.500000e+04  2.500000e+04   \n",
       "mean  -1.919913e-15 -4.298983e-16  6.954415e-16 -6.350676e-16 -2.079277e-15   \n",
       "std    1.000020e+00  1.000020e+00  1.000020e+00  1.000020e+00  1.000020e+00   \n",
       "min   -1.288965e-01 -2.010529e-01 -2.253249e-01 -1.742366e-01 -1.918075e-01   \n",
       "25%   -1.288965e-01 -2.010529e-01 -2.253249e-01 -1.742366e-01 -1.918075e-01   \n",
       "50%   -1.288965e-01 -2.010529e-01 -2.253249e-01 -1.742366e-01 -1.918075e-01   \n",
       "75%   -1.288965e-01 -2.010529e-01 -2.253249e-01 -1.742366e-01 -1.918075e-01   \n",
       "max    2.754411e+01  1.665766e+01  1.289073e+01  1.965274e+01  2.323167e+01   \n",
       "\n",
       "       ...         wrote          yeah          year         years  \\\n",
       "count  ...  2.500000e+04  2.500000e+04  2.500000e+04  2.500000e+04   \n",
       "mean   ... -3.933009e-16  5.111966e-16  2.106182e-16  6.824230e-16   \n",
       "std    ...  1.000020e+00  1.000020e+00  1.000020e+00  1.000020e+00   \n",
       "min    ... -1.332262e-01 -1.236582e-01 -2.500917e-01 -3.607842e-01   \n",
       "25%    ... -1.332262e-01 -1.236582e-01 -2.500917e-01 -3.607842e-01   \n",
       "50%    ... -1.332262e-01 -1.236582e-01 -2.500917e-01 -3.607842e-01   \n",
       "75%    ... -1.332262e-01 -1.236582e-01 -2.500917e-01 -3.607842e-01   \n",
       "max    ...  2.234428e+01  2.297604e+01  1.305537e+01  1.235532e+01   \n",
       "\n",
       "                yes           yet          york         young       younger  \\\n",
       "count  2.500000e+04  2.500000e+04  2.500000e+04  2.500000e+04  2.500000e+04   \n",
       "mean  -9.303203e-16 -8.339951e-16 -2.711003e-15  1.051639e-15 -2.090579e-15   \n",
       "std    1.000020e+00  1.000020e+00  1.000020e+00  1.000020e+00  1.000020e+00   \n",
       "min   -2.139107e-01 -2.858240e-01 -1.340179e-01 -2.953617e-01 -1.299937e-01   \n",
       "25%   -2.139107e-01 -2.858240e-01 -1.340179e-01 -2.953617e-01 -1.299937e-01   \n",
       "50%   -2.139107e-01 -2.858240e-01 -1.340179e-01 -2.953617e-01 -1.299937e-01   \n",
       "75%   -2.139107e-01 -2.858240e-01 -1.340179e-01 -2.953617e-01 -1.299937e-01   \n",
       "max    1.557978e+01  1.467985e+01  2.632046e+01  1.475529e+01  2.301481e+01   \n",
       "\n",
       "             zombie  \n",
       "count  2.500000e+04  \n",
       "mean   5.891365e-16  \n",
       "std    1.000020e+00  \n",
       "min   -8.818208e-02  \n",
       "25%   -8.818208e-02  \n",
       "50%   -8.818208e-02  \n",
       "75%   -8.818208e-02  \n",
       "max    2.766763e+01  \n",
       "\n",
       "[8 rows x 1001 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28439eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79998\\anaconda3\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- answer\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1 features, but StandardScaler is expecting 2 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumber\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m X_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_test)\n\u001b[0;32m      3\u001b[0m X_test\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mselect_dtypes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:973\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    970\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    972\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m--> 973\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1 features, but StandardScaler is expecting 2 features as input."
     ]
    }
   ],
   "source": [
    "X_test = sc.transform(test.select_dtypes(\"number\"))\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = test.select_dtypes(\"number\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89e2fbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.000</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.732</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.866</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.866</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.732</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id   answer\n",
       "count  25000.000  25000.0\n",
       "mean      -0.000      0.0\n",
       "std        1.000      1.0\n",
       "min       -1.732     -1.0\n",
       "25%       -0.866     -1.0\n",
       "50%        0.000      0.0\n",
       "75%        0.866      1.0\n",
       "max        1.732      1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da449c64",
   "metadata": {},
   "source": [
    "Среднее равно 0, все отлично"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8dfd0d",
   "metadata": {},
   "source": [
    "План работы:\n",
    "1. нам нужно классифицировать, поэтому самая очевидная модель для нашей задачи - логистическая регрессия \n",
    "* сделать tf-idf\n",
    "* построить логистическую регрессию на основе tf-idf\n",
    "2. Другой вариант - дерево решений\n",
    "* сделать 1 дерево\n",
    "* сделать случайный лес\n",
    "3. Попробовать метод К ближайших средних\n",
    "4. сравниь результаты всех подходов и выбрать лучший"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a1296",
   "metadata": {},
   "source": [
    "(Какая-то странная модель без тф-идф)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c39bfca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "330fbd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0,\n",
       "        'I fail to see the appeal of this series (which is supposed to be sci-fi). It\\'s really just \"let\\'s see what soap operatically happens this week\" and oh, the Cylons are involved through flashbacks.<br /><br />The Cylon \"babe\" that keeps nailing the other guy is pretty lame, it\\'s pretty obvious that T&A was added to the show. Every time she pops up I\\'m bewildered as to WTF is supposed to be going on. And don\\'t even try to bullsh*t me about \"story arcs\".<br /><br />It\\'s a soap opera with some CGI thrown-in. This is not science fiction aside from the original premise.<br /><br />This series is not everything it\\'s worked-up to be. If you like trendy, edgy, dodgy, jumpy, vague editor-on-crack camera work, this show might be for you. Since nerds seem to be raving about this show, it\\'s a clear indication that vocal nerds\\' opinions have been changed from Picard\\'s TNG.'],\n",
       "       [1,\n",
       "        \"According to the budget information given on this web site Dark Harvest had an estimated budget of $130,000. Where this money was spent I'm not exactly sure. Let me see....costumes...no...location and sets...hmmm, think not....special f/x...NOT...acting lessons...ah, no. Dark Harvest tells the epic tale of a young man who inherits a family farm in the hills of West Virginia. His girlfriend talks him into taking their friends up there to check the place out. Once there our intrepid hero learns that his great grandfather used a unique method for getting his crops to grow and now it's revenge time. Killer scarecrows out for revenge!!! Ewww scary. Well no, not really. We all know there have been some terrific movies made with very little money but this is not one of them. This film contains pretty much some of the worst acting and dialog I've ever seen. Terrible clichés with terrible delivery. All in all do not be fooled by the half way decent cover and avoid at all costs. I'd like to give the film makers at least a D- for trying but I'm afraid they didn't even do a good job with that. GRADE: F\"],\n",
       "       [2,\n",
       "        'I was looking forward to seeing Amanda Peet in another good role after recently renting \"The Whole Nine Yards\"--easily worth the rental, by the way--but this wasn\\'t it.<br /><br />I remembered that the trailer for \"Whipped\" was somewhat funny and the plot about three oversexed New Yorker twenty somethings all falling for and getting manipulated by the charming Ms. Peet was worth a shot. So, I convinced two friends one afternoon to come see this movie with me. This review is my penance.<br /><br />In the first act we have the three lead studs, recounting their conquests in a diner. What should have been funny, or at least telling, comes out rather pathetic. Was there any redeeming quality about the three men and their encounters that we were supposed to get out of this?<br /><br />[And while I don\\'t mind movies that are cheerfully vulgar, I kept wondering why no one in the diner turned around when the studs talk loudly about sexual and scatalogical details. They do this every week at the same diner? You would think someone would complain. Oh, wait, I forgot: two other diners do notice in one scene. But this is just a setup for a punchline. Everyone else in the diner is deaf.]<br /><br />The second act has the three studs all falling for Mia and then developing brain rot, failing to ask each other or her about what\\'s really happening between the four of them. And I kept asking myself, as the studs keep acting like they have been, what redeeming qualities does she see in them to stick with them longer than one date? Does she start out with brain rot? I kept hoping for Eric\\'s character, the married buddy, to become something more than simply the annoying punching bag in this act. His role is clearly to dispense advice on being married. But why do they even bother to talk to him when they won\\'t talk to each other? And his advice? Sheeesh!<br /><br />The third act resolves what plot there is but by this time I was looking at my watch. My friends told me they were still waiting for something genuinely funny to happen and I had to agree. The Scene That Explains All was adequate and managed to explain all of the questions and mysterious dialogue bits throughout the movie but we were just checking them off a list. (\"Oh, okay, that\\'s why Brad had that happen and Jonathan says this and...\")<br /><br />What laughs we made were from the stupidity of the plot than at anything amusing. Even the outtakes during the credits weren\\'t very funny. Ultimately I was left with nothing except a desire to warn people away from this movie.<br /><br />Rating: 3'],\n",
       "       ...,\n",
       "       [24997,\n",
       "        \"The thing with Ali G is that he takes the mick out of himself and his character. <br /><br />The humour is very much a 'like it or love it' brand of totally politically incorrect, irreverent and self effacing type.<br /><br />Personally I totally love this film, and so has everyone i have met who has seen it. You can watch it several times and pick new gags up each time. The humour is both aural and visual, and the timing is impeccable. The humour is probably very English, and specifically London, so its possible that non-English viewers may not get some of the humour. Think of yourself as a teenager and you will love it - especially if the likes of Kevin & Perry Go Large tickled you!\"],\n",
       "       [24998,\n",
       "        \"Upon completing this infernal piece of trash, a friend and I swore a solemn vow never to again speak of how we had just trashed away the last 90 minutes of our lives. This film is completely pointless, a two dimensional hero and heroin who we can't give a hoot whether or not they survive and some of the lamest villains to ever darken the screen of horror (or any other) genre. To further prove just how absolutely pointless this film was, I would have liked to add a plot synopsis, but I can't write fiction. All and all, the only reason I can think of that anyone would ever want to view this film is if they had just murdered their entire community and is looking for some self afflicted punishment that will haunt you for all following years to come!\"],\n",
       "       [24999,\n",
       "        'I found it a real task to sit through this film. The sound track was not the best and some of the accents made it difficult to understand what was being said. There was little to move the plot along and often the action simply stopped and there was a prolonged period of conversations which seemed extraneous to the movie. These conversations switched between family groups and the observer was left to try and piece together what the common thread was that tied them together. It is rare that I rate a film this low and do so in this case as the entire viewing experience left me thinking \"so what\" and \"why did I waste my time watching this.\"']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "418d7c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79998\\anaconda3\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- text\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- answer\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'I fail to see the appeal of this series (which is supposed to be sci-fi). It\\'s really just \"let\\'s see what soap operatically happens this week\" and oh, the Cylons are involved through flashbacks.<br /><br />The Cylon \"babe\" that keeps nailing the other guy is pretty lame, it\\'s pretty obvious that T&A was added to the show. Every time she pops up I\\'m bewildered as to WTF is supposed to be going on. And don\\'t even try to bullsh*t me about \"story arcs\".<br /><br />It\\'s a soap opera with some CGI thrown-in. This is not science fiction aside from the original premise.<br /><br />This series is not everything it\\'s worked-up to be. If you like trendy, edgy, dodgy, jumpy, vague editor-on-crack camera work, this show might be for you. Since nerds seem to be raving about this show, it\\'s a clear indication that vocal nerds\\' opinions have been changed from Picard\\'s TNG.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m5\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:425\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;124;03m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;124;03m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    427\u001b[0m         indices \u001b[38;5;241m=\u001b[39m (scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:407\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03mPredict confidence scores for samples.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03m    this class would be predicted.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    405\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 407\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'I fail to see the appeal of this series (which is supposed to be sci-fi). It\\'s really just \"let\\'s see what soap operatically happens this week\" and oh, the Cylons are involved through flashbacks.<br /><br />The Cylon \"babe\" that keeps nailing the other guy is pretty lame, it\\'s pretty obvious that T&A was added to the show. Every time she pops up I\\'m bewildered as to WTF is supposed to be going on. And don\\'t even try to bullsh*t me about \"story arcs\".<br /><br />It\\'s a soap opera with some CGI thrown-in. This is not science fiction aside from the original premise.<br /><br />This series is not everything it\\'s worked-up to be. If you like trendy, edgy, dodgy, jumpy, vague editor-on-crack camera work, this show might be for you. Since nerds seem to be raving about this show, it\\'s a clear indication that vocal nerds\\' opinions have been changed from Picard\\'s TNG.'"
     ]
    }
   ],
   "source": [
    "model.predict(X_test)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c09d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
